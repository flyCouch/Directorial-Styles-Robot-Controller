Here's the logical flow for processing that image:

Capture the Frame: The esp_camera_fb_get() function in your code already does this. It takes a picture and stores the pixel data in a frame buffer.

Thresholding: You will need to iterate through the pixel data in the frame buffer and filter for red pixels. You can do this by setting a threshold for the red component of the color. Any pixel with a red value above a certain number is considered part of an LED, while all others are ignored or set to black.

Find Blobs (Connected Components): After thresholding, your image will consist of a few bright spots (the LEDs) on a dark background. You'll need to write an algorithm to find these "blobs" of connected white pixels.

Calculate Centroids: For each blob you find, calculate its center of mass, or centroid. This will give you the (x, y) coordinates of each LED in the camera's frame, which is the data you need for your robot's pose.

This process will transform the raw image into a set of coordinate data, which you can then send to your desktop application.
